#!/usr/bin/env python3
"""
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞–º–∏ –¥–ª—è –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω–æ–≥–æ –±–æ—Ç–∞
–ê–≤—Ç–æ—Ä: 24vasilekk
–ü—É—Ç—å: manage_tokens.py (–≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞)

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
python manage_tokens.py --list                          # –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ —Ç–æ–∫–µ–Ω—ã
python manage_tokens.py --add "NEWTOKEN/USDT"          # –î–æ–±–∞–≤–∏—Ç—å —Ç–æ–∫–µ–Ω
python manage_tokens.py --remove "OLDTOKEN/USDT"       # –£–¥–∞–ª–∏—Ç—å —Ç–æ–∫–µ–Ω
python manage_tokens.py --check "NEWTOKEN/USDT"        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–æ–∫–µ–Ω
python manage_tokens.py --update-from-mexc             # –û–±–Ω–æ–≤–∏—Ç—å –∏–∑ MEXC
"""

import asyncio
import sys
import os
import json
import argparse
import yaml
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
from colorama import init, Fore, Style

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ü–≤–µ—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
init()

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ PYTHONPATH
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

class TokenManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–æ–º —Ç–æ–∫–µ–Ω–æ–≤"""
    
    def __init__(self):
        self.config_file = Path("config/settings.yaml")
        self.dex_client_file = Path("src/exchanges/dex_client.py")
        self.load_config()
    
    def load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
        except FileNotFoundError:
            print(f"‚ùå –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.config_file}")
            self.config = {'trading': {'symbols': []}}
    
    def save_config(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                yaml.dump(self.config, f, default_flow_style=False, 
                         allow_unicode=True, sort_keys=False)
            print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {self.config_file}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
    
    def get_tokens(self) -> list:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—É—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤"""
        return self.config.get('trading', {}).get('symbols', [])
    
    def add_token(self, symbol: str, search_term: str = None) -> bool:
        """–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω"""
        if not symbol.endswith('/USDT'):
            symbol += '/USDT'
        
        current_tokens = self.get_tokens()
        
        if symbol in current_tokens:
            print(f"‚ö†Ô∏è –¢–æ–∫–µ–Ω {symbol} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ —Å–ø–∏—Å–∫–µ")
            return False
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        current_tokens.append(symbol)
        self.config['trading']['symbols'] = current_tokens
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ DEX –∫–ª–∏–µ–Ω—Ç
        if search_term is None:
            search_term = symbol.split('/')[0].upper()
        
        self.update_dex_client_mapping(symbol, search_term, action='add')
        
        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Ç–æ–∫–µ–Ω: {symbol} -> {search_term}")
        return True
    
    def remove_token(self, symbol: str) -> bool:
        """–£–¥–∞–ª–∏—Ç—å —Ç–æ–∫–µ–Ω"""
        if not symbol.endswith('/USDT'):
            symbol += '/USDT'
        
        current_tokens = self.get_tokens()
        
        if symbol not in current_tokens:
            print(f"‚ö†Ô∏è –¢–æ–∫–µ–Ω {symbol} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–ø–∏—Å–∫–µ")
            return False
        
        # –£–¥–∞–ª—è–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        current_tokens.remove(symbol)
        self.config['trading']['symbols'] = current_tokens
        
        # –£–¥–∞–ª—è–µ–º –∏–∑ DEX –∫–ª–∏–µ–Ω—Ç–∞
        self.update_dex_client_mapping(symbol, action='remove')
        
        print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Ç–æ–∫–µ–Ω: {symbol}")
        return True
    
    def update_dex_client_mapping(self, symbol: str, search_term: str = None, action: str = 'add'):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –≤ DEX –∫–ª–∏–µ–Ω—Ç–µ"""
        try:
            with open(self.dex_client_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–µ–∫—Ü–∏—é token_search_mapping
            start_marker = "self.token_search_mapping = {"
            end_marker = "}"
            
            start_idx = content.find(start_marker)
            if start_idx == -1:
                print("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω token_search_mapping –≤ DEX –∫–ª–∏–µ–Ω—Ç–µ")
                return
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω–µ—Ü –º–∞–ø–ø–∏–Ω–≥–∞
            brace_count = 0
            end_idx = start_idx + len(start_marker)
            for i, char in enumerate(content[start_idx + len(start_marker):], start_idx + len(start_marker)):
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    if brace_count == 0:
                        end_idx = i
                        break
                    brace_count -= 1
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â–∏–π –º–∞–ø–ø–∏–Ω–≥
            mapping_section = content[start_idx:end_idx + 1]
            
            if action == 'add' and search_term:
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–æ–π
                new_line = f"            '{symbol}': '{search_term}',\n"
                insert_pos = mapping_section.rfind('}')
                updated_mapping = mapping_section[:insert_pos] + f"            '{symbol}': '{search_term}'\n        " + mapping_section[insert_pos:]
            
            elif action == 'remove':
                # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Å —Ç–æ–∫–µ–Ω–æ–º
                lines = mapping_section.split('\n')
                updated_lines = [line for line in lines if f"'{symbol}'" not in line]
                updated_mapping = '\n'.join(updated_lines)
            
            else:
                return
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª
            new_content = content[:start_idx] + updated_mapping + content[end_idx + 1:]
            
            with open(self.dex_client_file, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω DEX –∫–ª–∏–µ–Ω—Ç: {action} {symbol}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è DEX –∫–ª–∏–µ–Ω—Ç–∞: {e}")
    
    def list_tokens(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤"""
        tokens = self.get_tokens()
        
        print(f"\n{Fore.CYAN}üìä –¢–ï–ö–£–©–ò–ô –°–ü–ò–°–û–ö –¢–û–ö–ï–ù–û–í ({len(tokens)} —à—Ç.):{Style.RESET_ALL}")
        print("=" * 50)
        
        for i, token in enumerate(tokens, 1):
            print(f"{i:2d}. {token}")
        
        if not tokens:
            print("üì≠ –°–ø–∏—Å–æ–∫ –ø—É—Å—Ç")

async def check_token_availability(symbol: str):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–∞ –Ω–∞ MEXC –∏ DexScreener"""
    print(f"\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å {symbol}...")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ MEXC
    try:
        import ccxt
        mexc = ccxt.mexc({
            'apiKey': os.getenv('MEXC_API_KEY'),
            'secret': os.getenv('MEXC_SECRET'),
            'sandbox': True,
            'enableRateLimit': True
        })
        
        markets = mexc.load_markets()
        mexc_available = symbol in markets
        
        if mexc_available:
            print(f"  ‚úÖ MEXC: –î–æ—Å—Ç—É–ø–µ–Ω")
        else:
            print(f"  ‚ùå MEXC: –ù–ï –Ω–∞–π–¥–µ–Ω")
        
        mexc.close()
        
    except Exception as e:
        print(f"  ‚ùå MEXC: –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ - {e}")
        mexc_available = False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ DexScreener
    try:
        from src.exchanges.dex_client import DEXClient
        
        async with DEXClient() as dex_client:
            price_data = await dex_client.get_dex_price(symbol)
            
            if price_data:
                price = price_data['price']
                print(f"  ‚úÖ DEX: –î–æ—Å—Ç—É–ø–µ–Ω, —Ü–µ–Ω–∞ ${price:.8f}")
                dex_available = True
            else:
                print(f"  ‚ùå DEX: –ù–ï –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ—Ç –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏")
                dex_available = False
                
    except Exception as e:
        print(f"  ‚ùå DEX: –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ - {e}")
        dex_available = False
    
    # –ò—Ç–æ–≥
    if mexc_available and dex_available:
        print(f"  üéâ {Fore.GREEN}–ì–û–¢–û–í –ö –¢–û–†–ì–û–í–õ–ï{Style.RESET_ALL}")
        return True
    elif mexc_available or dex_available:
        print(f"  ‚ö†Ô∏è {Fore.YELLOW}–ß–ê–°–¢–ò–ß–ù–û –î–û–°–¢–£–ü–ï–ù{Style.RESET_ALL}")
        return False
    else:
        print(f"  üö® {Fore.RED}–ù–ï –î–û–°–¢–£–ü–ï–ù{Style.RESET_ALL}")
        return False

async def update_from_mexc():
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ MEXC"""
    print(f"\nüîÑ –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ —Å MEXC...")
    
    try:
        import ccxt
        mexc = ccxt.mexc({
            'apiKey': os.getenv('MEXC_API_KEY'),
            'secret': os.getenv('MEXC_SECRET'),
            'sandbox': True,
            'enableRateLimit': True
        })
        
        markets = mexc.load_markets()
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ USDT –ø–∞—Ä—ã
        usdt_pairs = [symbol for symbol in markets.keys() if symbol.endswith('/USDT')]
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(usdt_pairs)} USDT –ø–∞—Ä –Ω–∞ MEXC")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 50 –¥–ª—è –≤—ã–±–æ—Ä–∞
        print(f"\n{Fore.CYAN}üéØ –î–û–°–¢–£–ü–ù–´–ï –î–õ–Ø –î–û–ë–ê–í–õ–ï–ù–ò–Ø (–ø–µ—Ä–≤—ã–µ 50):{Style.RESET_ALL}")
        for i, pair in enumerate(usdt_pairs[:50], 1):
            print(f"{i:2d}. {pair}")
        
        print(f"\nüí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: python manage_tokens.py --add \"SYMBOL/USDT\"")
        
        mexc.close()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö MEXC: {e}")

def parse_args():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(description='–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞–º–∏ –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω–æ–≥–æ –±–æ—Ç–∞')
    
    parser.add_argument('--list', action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ —Ç–µ–∫—É—â–∏–µ —Ç–æ–∫–µ–Ω—ã')
    parser.add_argument('--add', metavar='SYMBOL',
                       help='–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä: NEWTOKEN/USDT)')
    parser.add_argument('--remove', metavar='SYMBOL',
                       help='–£–¥–∞–ª–∏—Ç—å —Ç–æ–∫–µ–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä: OLDTOKEN/USDT)')
    parser.add_argument('--check', metavar='SYMBOL',
                       help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞')
    parser.add_argument('--search-term', metavar='TERM',
                       help='–ü–æ–∏—Å–∫–æ–≤—ã–π —Ç–µ—Ä–º–∏–Ω –¥–ª—è DexScreener (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)')
    parser.add_argument('--update-from-mexc', action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã —Å MEXC')
    
    return parser.parse_args()

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    args = parse_args()
    
    print(f"{Fore.CYAN}üîß –ú–ï–ù–ï–î–ñ–ï–† –¢–û–ö–ï–ù–û–í –ê–†–ë–ò–¢–†–ê–ñ–ù–û–ì–û –ë–û–¢–ê")
    print("–ê–≤—Ç–æ—Ä: 24vasilekk")
    print("=" * 50)
    
    manager = TokenManager()
    
    if args.list:
        manager.list_tokens()
    
    elif args.add:
        symbol = args.add.upper()
        search_term = args.search_term
        
        if manager.add_token(symbol, search_term):
            manager.save_config()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
            await check_token_availability(symbol)
    
    elif args.remove:
        symbol = args.remove.upper()
        
        if manager.remove_token(symbol):
            manager.save_config()
    
    elif args.check:
        symbol = args.check.upper()
        await check_token_availability(symbol)
    
    elif args.update_from_mexc:
        await update_from_mexc()
    
    else:
        print("‚ùå –ù–µ —É–∫–∞–∑–∞–Ω–æ –¥–µ–π—Å—Ç–≤–∏–µ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --help –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏")
        print("\nüí° –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:")
        print("   python manage_tokens.py --list")
        print("   python manage_tokens.py --add \"NEWTOKEN/USDT\"")
        print("   python manage_tokens.py --remove \"OLDTOKEN/USDT\"")
        print("   python manage_tokens.py --check \"PEPE/USDT\"")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print(f"\n{Fore.YELLOW}‚èπÔ∏è –û–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞{Style.RESET_ALL}")
    except Exception as e:
        print(f"\n{Fore.RED}‚ùå –û—à–∏–±–∫–∞: {e}{Style.RESET_ALL}")